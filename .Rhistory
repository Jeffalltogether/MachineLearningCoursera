pred <- predict(LDA, trainSA)
missClass(trainSA$chd, pred)
pred <- predict(LDA, testSA)
missClass(testSA$chd, pred)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
trainDF <- data.frame(vowel.train)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
trainDF <- data.frame(vowel.train)
testDF <- data.frame(vowel.test)
trainDF$y <- factor(trainDF$y)
testDF$y <- factor(testDF$y)
set.seed(33833)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
trainDF <- data.frame(vowel.train)
testDF <- data.frame(vowel.test)
trainDF$y <- factor(trainDF$y)
testDF$y <- factor(testDF$y)
set.seed(33833)
model <- train(y ~ ., method = "rf", data = trainDF)
varImp(model)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
trainDF <- data.frame(vowel.train)
testDF <- data.frame(vowel.test)
trainDF$y <- factor(trainDF$y)
testDF$y <- factor(testDF$y)
set.seed(33833)
model <- train(y ~ ., method = "rf", data = trainDF)
varImp(model)
DF <- rbind(trainDF, testDF)
set.seed(33833)
model <- train(y ~ ., method = "rf", data = DF)
varImp(model)
?varImp
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
trainDF <- data.frame(vowel.train)
testDF <- data.frame(vowel.test)
trainDF$y <- factor(trainDF$y)
testDF$y <- factor(testDF$y)
DF <- rbind(trainDF, testDF)
set.seed(33833)
model <- train(y ~ ., method = "rf", data = testDF)
varImp(model)
model <- train(y ~ ., method = "rf", data = trainDF)
varImp(model)
set.seed(33833)
model <- train(y ~ ., method = "rf", data = DF)
varImp(model)
varImp.RandomForest(model)
varImp.RandomForest(model)
order(varImp(model), decreasing = T)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
caret
?caret
??caret
model <- train(y ~ ., data = trainDF, method = "rf", prox=TRUE)
order(varImp(model), decreasing = T)
varImp(model)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
set.seed(33833)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
set.seed(33833)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
set.seed(33833)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
set.seed(33833)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
set.seed(33833)
model <- train(y ~ ., data = trainDF, method="rf")
order(varImp(model), decreasing = T)
pred <- predict(model, testDF)
confusionMatrix(testDF$y, pred)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
# Coronary Heart Disease (chd) as the outcome and age at onset, current alcohol
# consumption, obesity levels, cumulative tabacco, type-A behavior,
# and low density lipoprotein cholesterol as predictors
LDA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", family = "binomial", data = trainSA)
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
pred <- predict(LDA, trainSA)
missClass(trainSA$chd, pred)
pred <- predict(LDA, testSA)
missClass(testSA$chd, pred)
pred <- predict(LDA, trainSA)
train <- missClass(trainSA$chd, pred)
pred <- predict(LDA, testSA)
test <- missClass(testSA$chd, pred)
print("training missclassification", train, "testing missclassification", test)
print("training missclassification", train, "testing missclassification", test)
print(test, train)
pred <- predict(LDA, trainSA)
train <- missClass(trainSA$chd, pred)
pred <- predict(LDA, testSA)
test <- missClass(testSA$chd, pred)
test
train
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
trainDF <- data.frame(vowel.train)
testDF <- data.frame(vowel.test)
trainDF$y <- factor(trainDF$y)
testDF$y <- factor(testDF$y)
DF <- rbind(trainDF, testDF)
set.seed(33833)
model <- randomForest(y ~ ., data = trainDF)
order(varImp(model), decreasing = T)
## Research the prevalence of the disease in the population
prev = 0.5 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.86
sp = 0.86
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Determine NPV0 and PPV0
currentSE = 0.75   # sensitivity of current test to beat
currentSP = 0.75   # specificity of current test to beat
## Positive and negative predictive values
PPV0 = (prev*currentSE)/(prev*currentSE+(1-prev)*(1-currentSP))
NPV0 = ((1-prev)*currentSP)/(prev*(1-currentSE)+(1-prev)*currentSP)
## Calculate Sample Size
result <- nPV(se, sp, prev, NPV0, PPV0,
NPVpower = 0.8, PPVpower = 0.8,
rangeP = c(0.05, 0.95), nsteps = 30,
alpha = 0.05, setnames = NULL)
print(result)
# outDAT a data.frame showing the parameter settings (in rows) and the input parameters se, sp, prev, NPV0, PPV0, NPVpower, PPVpower, trueNPV, truePPV
# nlist a list with an element for each parameter setting in OUTDAT, listing the results of nNPV, and nPPV
# NSETS a single (integer), the number of parameter sets
# nsteps a single (integer), the number of steps in the range of proportions of true positives
# rangeP the input range of the proportion of true positives
# propP the resulting sequence of proportions of true positives considere
## Plot Result
plotnPV(result, log = "y", NPVpar = list(col=3, lwd=2, lty=1),
PPVpar = list(col=4, lwd=2, lty=1),
xlab="Proportion of true positives in study cohort, n1/(n0+n1) \n n0 = Shallow Burn     n1 = Deep Burn",
ylab="Total sample size, (n0+n1)")
abline(v=prev, col = "red")
#main="Figure Pilot Study \nSample Size Estimate")
library(bdpv)
## Research the prevalence of the disease in the population
prev = 0.5 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.86
sp = 0.86
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Determine NPV0 and PPV0
currentSE = 0.75   # sensitivity of current test to beat
currentSP = 0.75   # specificity of current test to beat
## Positive and negative predictive values
PPV0 = (prev*currentSE)/(prev*currentSE+(1-prev)*(1-currentSP))
NPV0 = ((1-prev)*currentSP)/(prev*(1-currentSE)+(1-prev)*currentSP)
## Calculate Sample Size
result <- nPV(se, sp, prev, NPV0, PPV0,
NPVpower = 0.8, PPVpower = 0.8,
rangeP = c(0.05, 0.95), nsteps = 30,
alpha = 0.05, setnames = NULL)
print(result)
# outDAT a data.frame showing the parameter settings (in rows) and the input parameters se, sp, prev, NPV0, PPV0, NPVpower, PPVpower, trueNPV, truePPV
# nlist a list with an element for each parameter setting in OUTDAT, listing the results of nNPV, and nPPV
# NSETS a single (integer), the number of parameter sets
# nsteps a single (integer), the number of steps in the range of proportions of true positives
# rangeP the input range of the proportion of true positives
# propP the resulting sequence of proportions of true positives considere
## Plot Result
plotnPV(result, log = "y", NPVpar = list(col=3, lwd=2, lty=1),
PPVpar = list(col=4, lwd=2, lty=1),
xlab="Proportion of true positives in study cohort, n1/(n0+n1) \n n0 = Shallow Burn     n1 = Deep Burn",
ylab="Total sample size, (n0+n1)")
abline(v=prev, col = "red")
#main="Figure Pilot Study \nSample Size Estimate")
str(nPV)
str(result)
result[[1]]
result[[2]]
result[[3]]
result[[4]]
result[[5]]
result[[7]]
result[[6]]
result[[2]]
prev = 0.2 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.86
sp = 0.86
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Research the prevalence of the disease in the population
prev = 0.5 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.86
sp = 0.86
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Determine NPV0 and PPV0
currentSE = 0.75   # sensitivity of current test to beat
currentSP = 0.75   # specificity of current test to beat
## Positive and negative predictive values
PPV0 = (prev*currentSE)/(prev*currentSE+(1-prev)*(1-currentSP))
NPV0 = ((1-prev)*currentSP)/(prev*(1-currentSE)+(1-prev)*currentSP)
## Calculate Sample Size
result <- nPV(se, sp, prev, NPV0, PPV0,
NPVpower = 0.8, PPVpower = 0.8,
rangeP = c(0.05, 0.95), nsteps = 30,
alpha = 0.05, setnames = NULL)
print(result)
# outDAT a data.frame showing the parameter settings (in rows) and the input parameters se, sp, prev, NPV0, PPV0, NPVpower, PPVpower, trueNPV, truePPV
# nlist a list with an element for each parameter setting in OUTDAT, listing the results of nNPV, and nPPV
# NSETS a single (integer), the number of parameter sets
# nsteps a single (integer), the number of steps in the range of proportions of true positives
# rangeP the input range of the proportion of true positives
# propP the resulting sequence of proportions of true positives considere
## Plot Result
plotnPV(result, log = "y", NPVpar = list(col=3, lwd=2, lty=1),
PPVpar = list(col=4, lwd=2, lty=1),
xlab="Proportion of true positives in study cohort, n1/(n0+n1) \n n0 = Shallow Burn     n1 = Deep Burn",
ylab="Total sample size, (n0+n1)")
abline(v=prev, col = "red")
#main="Figure Pilot Study \nSample Size Estimate")
samsize.mcnemar <- function(pi.01, pi.10, alpha, beta, sided)
{
pi.d <- (pi.01 + pi.10)
N <- (qnorm(1 - alpha/sided) * sqrt(pi.d) + qnorm(1 - beta) *
sqrt(pi.d - (pi.01 - pi.10)^2))^2/(pi.01 - pi.10)^2
return(ceiling(N))
}
# in my case, I am assuming that the 0 to 1 change will be 0.13 and that no
# one will change from 1 to 0
samsize.mcnemar(pi.01 = 0.13, pi.10 = 0, alpha = 0.1, beta = 0.2, sided = 2)
samsize.mcnemar(pi.01 = 0.11, pi.10 = 0, alpha = 0.1, beta = 0.2, sided = 2)
1-.86
samsize.mcnemar(pi.01 = 0.11, pi.10 = .2, alpha = 0.1, beta = 0.2, sided = 2)
library(caret)
predictors = data.frame(ozone=ozone$ozone)
library(MASS)
predictors = data.frame(ozone=ozone$ozone)
library(datasets)
predictors = data.frame(ozone=ozone$ozone)
??ozone
library(ELSR)
library(elsr)
library(ElemStatLearn)
predictors = data.frame(ozone=ozone$ozone)
?bag
?bagControl
?trcontrol
?trControl
??trcontrol
?qda
??Mass
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
QDAbag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = qda,
predict = predict.qda
aggregate = qda$aggregate)
library(caret)
library(ElemStatLearn)
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
QDAbag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = qda,
predict = predict.qda,
aggregate = qda$aggregate))
qda$aggregate
library(caret)
#Question 1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
training <- as.data.frame(data(vowel.train))
testing <- as.data.frame(data(vowel.test))
set.seed(33833)
rforest <- train(factor(y) ~ ., method = "rf", data=training)
colnames(training)
data(vowel.train)
data(vowel.test)
training <- as.data.frame(vowel.train)
testing <- as.data.frame(vowel.test)
set.seed(33833)
rforest <- train(factor(y) ~ ., method = "rf", data=training)
boosting <- train(factor(y) ~ ., method = "gbm", data=training)
class(testing$y)
training <- as.factor(training$y)
testing <- as.factor(testing$y)
set.seed(33833)
rforest <- train(y ~ ., method = "rf", data=training)
boosting <- train(y ~ ., method = "gbm", data=training)
pred <- predict(rforest, testing)
confusionMatrix(testing$y, pred)
rforest <- train(y ~ ., method = "rf", data=training)
data(vowel.train)
data(vowel.test)
training <- as.data.frame(vowel.train)
testing <- as.data.frame(vowel.test)
training$y <- as.factor(training$y)
testing$y <- as.factor(testing$y)
set.seed(33833)
rforest <- train(y ~ ., method = "rf", data=training)
boosting <- train(y ~ ., method = "gbm", data=training)
pred1 <- predict(rforest, testing)
confusionMatrix(testing$y, pred1)
pred2 <- predict(boosting, testing)
confusionMatrix(testing$y, pred2)
predDF <- data.frame(pred1, pred2, y = testing$y)
combModFit <- train(y ~., method="gam", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(predDF$y, combPred)
class(testing$y)
?gam
combModFit <- train(y ~., method="gam", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(predDF$y, combPred)
library(caret)
#Question 1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
training <- as.data.frame(vowel.train)
testing <- as.data.frame(vowel.test)
training$y <- as.factor(training$y)
testing$y <- as.factor(testing$y)
set.seed(33833)
rforest <- train(y ~ ., method = "rf", data=training)
boosting <- train(y ~ ., method = "gbm", data=training)
pred1 <- predict(rforest, testing)
confusionMatrix(testing$y, pred1)
pred2 <- predict(boosting, testing)
confusionMatrix(testing$y, pred2)
predDF <- data.frame(pred1, pred2, y = testing$y)
combModFit <- train(y ~., method="gam", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(predDF$y, combPred)
?gam
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rforest <- train(diagnosis ~ ., method = "rf", data=training)
boosting <- train(diagnosis ~ ., method = "gbm", data=training)
lda <- train(diagnosis ~ ., method = "gbm", data=training)
pred1 <- predict(rforest, testing)
confusionMatrix(testing$y, pred1)
pred2 <- predict(boosting, testing)
confusionMatrix(testing$y, pred2)
pred3 <- predict(boosting, testing)
confusionMatrix(testing$y, pred3)
pred1 <- predict(rforest, testing)
confusionMatrix(testing$diagnosis, pred1)
pred2 <- predict(boosting, testing)
confusionMatrix(testing$diagnosis, pred2)
pred3 <- predict(boosting, testing)
confusionMatrix(testing$diagnosis, pred3)
pred3 <- predict(lda, testing)
confusionMatrix(testing$diagnosis, pred3)
predDF <- data.frame(pred1, pred2,pred3, y = testing$diagnosis)
combModFit <- train(diagnosis ~., method="gam", data = predDF)
View(predDF)
predDF <- data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~., method="gam", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(predDF$y, combPred)
combPred <- predict(combModFit, predDF)
confusionMatrix(predDF$diagnosis, combPred)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso <- train(CompressiveStrength ~ ., method = "lasso", data = training)
?plot.enet
plot(model$lasso, "norm",   label=TRUE)
plot(lasso$glmnet.fit, "norm",   label=TRUE)
plot(lasso$glmnet.fit, "CompressiveStrength",   label=TRUE)
plot(lasso$glmnet.fit, concrete$CompressiveStrength,   label=TRUE)
plot(lasso, concrete$CompressiveStrength,   label=TRUE)
names(lass)
names(lasso)
?glmnet
names(summary(lasso))
summary(lasso)
names(lass)
summary(lasso)
names(lasso)
lasso$method
lasso$modelinfo
lasso[[3]]
lasso[[4]]
lasso[[5]]
lasso[[6]]
lasso[[7]]
lasso[[8]]
lasso[[9]]
lasso[[10]]
plot(lasso[[10]])
plot.enet(fit$finalModel, xvar = "penalty", use.color = TRUE)
plot.enet(lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("gaData.csv")
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/PracticalMachineLearning/MachineLearningCoursera")
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/PracticalMachineLearning/MachineLearningCoursera")
library(lubridate) # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
forcastModel <- bats(training)
head(training)
forcastModel <- bats(tstrain)
head(tstrain)
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/PracticalMachineLearning/MachineLearningCoursera")
library(lubridate) # For year() function below
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
head(tstrain)
head(tstrain, 50)
head(tstrain, 500)
?forcast
??forcaast
??forecast
pred1 <- predict(forcastModel, testing)
accuracy(forcastModel, testing)
plot(forcastModel)
accuracy(forcastModel)
h <- dim(testing)[1]
# forecast the model for remaining time points
fcast <- forecast(fit, level = 95, h = h)
# get the accuracy
accuracy(fcast, testing$visitsTumblr)
# check what percentage of times that the actual number of visitors was within
# 95% confidence interval
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
h <- dim(testing)[1]
h
