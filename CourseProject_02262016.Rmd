---
title: "Practical Machine Learning Course Project: Predicting proper exercise form with wearable accelerometer sensor data"
author: "Jeffrey Thatcher"
date: "Monday, February 15, 2016"
output: html_document
---

You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

#1.0 Background

Machine learning model based on the exercise sensor data collected by Velloso et al, 2013.[1]
Simply using the raw accelerometer data a prediction model was built to correctly classify accelerometer data from 20 Test cases.  The outcome variable levels are A, B, C, D, and E. A comes from exercise that was performed correctly while B - E were from the same exercises that were performed incorrectly. The goal of the algorithm is to correctly classify how each person in the test set was performing their exercise.


[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th Augmented Human (AH) International Conference in cooperation with ACM SIGCHI (Augmented Human'13) . Stuttgart, Germany: ACM SIGCHI, 2013. 

#2.0 Methods
##2.1 Raw Sensor Data
The raw data was loaded and, by using the time stamp variables, a plot of the accelerometer data is generated. The data represents the sensor data from a person doing a biceps curl correctly (Fig.1 - green) or incorrectly (Fig.1 - red).

```{r warning=F, message=F, echo=F, cache=F}
### Set WD, Load Libraries and Data
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/PracticalMachineLearning/PracticalMachineLearning")
library(caret)
library(ggplot2)
library(moments)
library(stringr)
library(dplyr)
library(tidyr)
source("multiplot.R")
```

```{r warning=F, message=F, echo=F, cache=F}
###load training dataset
trainData <- as.data.frame(read.csv("pml-training.csv", na.strings=c("","NA")))
quizData <- as.data.frame(read.csv("pml-testing.csv", na.strings=c("","NA")))

###generate ID variable
trainData$windowID <- paste(trainData$user_name, trainData$num_window,
                        trainData$classe,
                        sep=" ")

###Create unique identifier column for each user's activities
trainData$exerciseID <- paste(trainData$user_name,
                        trainData$classe, 
                        sep=" ")

###Graph timeseries
# generate times for each activity
trainData$time <- paste(str_sub(trainData$raw_timestamp_part_1, -5, -1),
                        substr(trainData$raw_timestamp_part_2, 1, 3), 
                        sep="")

trainData <- trainData %>%
        group_by(classe) %>%
        group_by(user_name) %>%
        mutate(newTime = as.numeric(time) - min(as.numeric(time)))
```

##2.2 Plot of sensor data from one user
```{r warning=F, message=F, echo=F, fig.height=6, fig.width=6, cache=F}
# plot timeseries for a few data points
p1 <- ggplot(trainData[grep("carlitos A", trainData$exerciseID),], aes(newTime, gyros_arm_y, color=user_name))+geom_line(color="green")

p2 <- ggplot(trainData[grep("carlitos B", trainData$exerciseID),], aes(newTime, gyros_arm_y, color=user_name))+geom_line(color="red")

p3 <- ggplot(trainData[grep("carlitos C", trainData$exerciseID),], aes(newTime, gyros_arm_y, color=user_name))+geom_line(color="red")

p4 <- ggplot(trainData[grep("carlitos D", trainData$exerciseID),], aes(newTime, gyros_arm_y, color=user_name))+geom_line(color="red")

p5 <- ggplot(trainData[grep("carlitos E", trainData$exerciseID),], aes(newTime, gyros_arm_y, color=user_name))+geom_line(color="red")

multiplot(p1, p2, p3, p4, p5, cols = 2)
```

**Figure 1**. This figure represents the data collected from the `gyros_arm_z` sensor taken from the exerciser Carlitos while doing a biceps curl in five different ways. (green) correct curl body movement; (red) incorrect body movement.

##2.3 Cleaning Data
To clean the data first, the column with no predictive values were removed, such as the time stamp and row number columns.  Following that, columns that were empty and those that contained missing data (NA) were removed.

```{r warning=F, message=F, echo=T, cache=F}
###Eliminate columns with missing and unrelated
cleanData <- function(dataframe){

        #Eliminate columns with unrelated data
        colToRemove <- c(grep("X", colnames(dataframe)),
                         grep("user_name", colnames(dataframe)),
                         grep("raw_timestamp_part_1", colnames(dataframe)),
                         grep("raw_timestamp_part_2", colnames(dataframe)),
                         grep("cvtd_timestamp", colnames(dataframe)),
                         grep("new_window", colnames(dataframe)),
                         grep("num_window", colnames(dataframe)),
                         grep("time", colnames(dataframe)),
                         grep("newTime", colnames(dataframe)),
                         grep("exerciseID", colnames(dataframe)),
                         grep("windowID", colnames(dataframe)))
        dataframe <- dataframe[,-colToRemove]
        
        #Eliminate columns with NA values
        dataframe <- dataframe[, colSums(is.na(dataframe)) == 0]

        return(dataframe)
}

trainData <- cleanData(trainData)
quizData <- cleanData(quizData)
```


##2.4 Data Partitions
Once the sensor data was cleaned it was then prepared for predictive modeling. To prepare the data, the training dataset was separated into "Training" and "Test" datasets using the `caret` package's `createDataPartition` function.

```{r warning=F, message=F, echo=T, cache=F}
#Separate training and test data
# We will remove one person from each level of the variable `classe` as the test set
set.seed(1000)
trainIndex = createDataPartition(trainData$classe, p = 0.60,list=FALSE)
training = trainData[trainIndex,]
testing = trainData[-trainIndex,]
```

#3.0 Machine Learning
Three predictive models were trained including: linear discriminant analysis (LDA); decision Tree; and bagged decision tree. Accuracy was determined by cross-validation for each of the three models and then we applied the model to the "testing" data set that was partitioned in section *2.4 Data Partitions*.  The final model was selected based on the "testing"" data set accuracy. Testing data results are presented as a confusion matrix using the `confusionMatrix` function from the `caret` package.

##3.1 Linear Discriminant Analysis
```{r warning=F, message=F, echo=T, cache=F}
### Train lda Classifier
#fit model
Lda <- train(classe ~ ., method="lda", data=training)
        
#predict test data
pred <- predict(Lda, testing)
confusionMatrix(testing$classe, pred)
```


##3.2 Trees
```{r warning=F, message=F, fig.height=6, fig.width=6, cache=F}
library(rattle)

#fit model
tree <- train(classe ~ ., method="rpart", data=training)

#predict test data
pred <- predict(tree, testing)
confusionMatrix(testing$classe, pred)

fancyRpartPlot(tree$finalModel)
```

##3.3 Bagging
```{r warning=F, message=F, fig.height=6, fig.width=6, cache=T}
#fit model
bagging <- train(classe ~ ., method="treebag", data=training, nbagg = 25)

#predict test data
pred <- predict(bagging, testing)
confusionMatrix(testing$classe, pred)

fancyRpartPlot(summary(bagging)$mtrees[[25]]$btree)
```

**Figure 3**. One of the 25 trees built in the bagged trees model that was aggregated to form the final model.

#4.0 Results
Final results in predicting the hold-out "testing" data set show that LDA was 69% accurate, the decision tree was 55% accurate, and the bagged trees model was 99% accurate. 

The bootstrap aggregated decision tree model built using the treebag method in the `caret` function performed best of the three models tested. The tuning parameter `nbagg` was set to 25, which means the model is the result of aggregating 25 decision trees generated from bootstrapped training data. The model may perform better with more aggregates, the consequence of which may be even more reduced variance in the model.  However, it is likely that the tradeoff between processing time to generate the model and increase in accuracy is not valuable considering the model is already very accurate anf it takes about 5 min to generate the model on a standard laptop computer (Core i7, 8GB RAM).
